{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Théo Cornille - Mirwaisse Djanbaz - Luc Gibaud - Cédric des Lauriers\n",
    "# Learning and Memorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnistfile =\"mnist.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "import dataset_loader\n",
    "train_set, valid_set, test_set = dataset_loader.load_mnist(mnistfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set[0] = train_set[0][:1000]\n",
    "train_set[1] = train_set[1][:1000]\n",
    "valid_set[0] = valid_set[0][:1000]\n",
    "valid_set[1] = valid_set[1][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1180f00f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exemple d'image du MNIST\n",
    "img_id = 42\n",
    "plt.imshow(train_set[0][img_id].reshape(28,28) , cmap='Greys') \n",
    "print(\"label: \" + str(train_set[1][img_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Création du nouveau label binaire : 0 si ancien label < 5 et 1 si >= 5\n",
    "train_set_binarized_labels = (train_set[1] >= 5).astype(int)\n",
    "valid_set_binarized_labels = (valid_set[1] >= 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fonction servant à binariser les valeurs de chaque pixels d'une image\n",
    "def binarise(img, s=0.5):\n",
    "    nbr_pixels = len(img)\n",
    "    L=np.zeros(nbr_pixels)\n",
    "    for i in range(nbr_pixels) :\n",
    "        if img[i]>s :\n",
    "            L[i]=1\n",
    "        else :\n",
    "            L[i]=0\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label binaire: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11814df28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exemple d'image du MNIST binarisée avec label binaire\n",
    "plt.imshow(binarise(train_set[0][img_id],s=0.5).reshape(28,28) , cmap='Greys') \n",
    "print(\"label binaire: \" + str(train_set_binarized_labels[img_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarisation du dataset\n",
    "for i in range (train_set[0].shape[0]):\n",
    "    train_set[0][i]=binarise(train_set[0][i])\n",
    "\n",
    "for i in range (valid_set[0].shape[0]):\n",
    "    valid_set[0][i]=binarise(valid_set[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Déclaration de X_train, y_train, X_test, y_test\n",
    "X_train = train_set[0].astype(int)\n",
    "y_train = train_set_binarized_labels\n",
    "\n",
    "X_test = valid_set[0].astype(int)\n",
    "y_test = valid_set_binarized_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class Memorization:\n",
    "    \n",
    "    \"\"\"\n",
    "    Initialise le modèle.\n",
    "    \"\"\"\n",
    "    def __init__(self, layers, k):\n",
    "        self.layers = layers # liste des couches de luts\n",
    "        self.k = k # nombre d'entrée par lut\n",
    "        self.list_luts = [] # liste des luts\n",
    "        self.dict = self.init_dict()\n",
    "        self.make_list_luts()\n",
    "\n",
    "        self.list_link = [] # liste des liaisons entre luts\n",
    "    \n",
    "    \"\"\"\n",
    "    Crée la liste des liens entre les luts. \n",
    "        list_luts[i][j] correspond à l'ensemble des luts de la couche i qu'il faut ordonner \n",
    "        pour obtenir le jème lut de la couche i+1\n",
    "    \"\"\"\n",
    "    def make_list_luts(self):\n",
    "        self.list_luts = []\n",
    "\n",
    "        L = []\n",
    "        \n",
    "        #génère la combinaison aléatoire de taille k pour chacune des couches et les ajoute dans une liste 'list_luts'\n",
    "        for layer in range(1, len(self.layers)):\n",
    "            L = []\n",
    "            for i in range(self.layers[layer]):\n",
    "                L.append(np.random.randint(0, self.layers[layer-1], self.k))\n",
    "            self.list_luts.append(L)\n",
    "            \n",
    "    \"\"\"\n",
    "    Sert à initialiser un dictionnaire. \n",
    "    Le dictionnaire possède pour clés l'ensemble des nombres en binaire de 0 à 2**self.k-1\n",
    "    Toutes les valeurs sont nulles\n",
    "    \"\"\"\n",
    "    def init_dict(self):\n",
    "        dict_ = {}\n",
    "        for i in range(2**self.k):\n",
    "            x = (\"0\"*self.k + str(bin(i))[2:])[-self.k:]\n",
    "            dict_[x] = 0\n",
    "        return dict_\n",
    "    \n",
    "    \"\"\"\n",
    "    Entraînement du modèle.\n",
    "    Mets notamment à jour list_link :\n",
    "        list_link[i][j] est un dictionnaire qui permet, pour le lut j de la couche i+1,\n",
    "        de transformer la combinaison des k luts correspondans de la couche i en un nombre binaire (0 ou 1)\n",
    "    \"\"\"\n",
    "    def fit(self, X_train, y_train, print_training_accuracy = False):\n",
    "        #Display training accuracy for the first layer (layer 0)\n",
    "        if print_training_accuracy:\n",
    "                print(\"Layer = \" + str(0) \n",
    "                      + \" | Lut count = \" + (str(self.layers[0]) + \"    \")[:5]\n",
    "                      + \" | Training Accuracy = \" + str(self.accuracy(X_train, y_train)))\n",
    "                \n",
    "        n = len(X_train)\n",
    "        \n",
    "        list_computed = [X_train] #initialise la liste des couches qui vont être calculées\n",
    "        self.list_link = [] # liste des liaisons entre luts\n",
    "\n",
    "        # Entraînement couche par couche\n",
    "        for layer in range(1, len(self.layers)): #numero de la couche\n",
    "            layer_luts = self.list_luts[layer - 1] #liste des luts de la couche précédente et de taille k (combinaison aléatoire)\n",
    "\n",
    "            last_computed_layer = list_computed[-1] #récupère la dernière couche\n",
    "\n",
    "            link = []\n",
    "            next_computed_layer = [[0 for x in range(self.layers[layer])] for y in range(n)] #initialiste la couche suivante \n",
    "                                                                                             #(taille de la couche suivant * nombre d'exemples dans le dataset)\n",
    "            \n",
    "            for i in range(self.layers[layer]): #parcourt la taille de la couche pour chaque couche\n",
    "                dict_positif = self.dict.copy() #init du dictionnaire stockant le nombre de valeurs positives\n",
    "                dict_negatif = self.dict.copy() #init du dictionnaire stockant le nombre de valeurs négatives\n",
    "\n",
    "                for j in range(n): #parcourt le nombre d'exemples dans le dataset\n",
    "                    s = \"\"\n",
    "                    for z in range(self.k): #parcourt la taille k pour chaque exemple\n",
    "                        s += str(last_computed_layer[j][layer_luts[i][z]]) #donne la valeur binaire pour chaque exemple (j) grâce à la combinaison aléatoire des luts de la couche précédente \n",
    "                    next_computed_layer[j][i] = s #stocke la valeur binaire dans la nouvelle couche à la position (j=numero d'exemples, i=numero dans la taille de la couche)\n",
    "                    dict_negatif[s] += (y_train[j] == 0).astype(int) #stocke dans le dict neg pour la clé binaire, le nombre de valeurs negatives dans le dataset\n",
    "                    dict_positif[s] += (y_train[j] == 1).astype(int) #stocke dans le dict pos pour la clé binaire, le nombre de valeurs positive dans le dataset\n",
    "\n",
    "                dict_ = self.dict.copy()\n",
    "                \n",
    "                #prédiction finale obtenu par la comparaison du nombre de valeurs positives par rapport aux nombres de valeurs négatives\n",
    "                for l in dict_.keys():\n",
    "                    if dict_positif[l] > dict_negatif[l]:\n",
    "                        dict_[l] = 1\n",
    "                    elif dict_positif[l] < dict_negatif[l]:\n",
    "                        dict_[l] = 0\n",
    "                    else :\n",
    "                        dict_[l] = np.random.randint(2)\n",
    "\n",
    "                #attribut la valeur finale pour la nouvelle couche à la position j(num exemple pour chaque exemple), i(num taille de la couche)\n",
    "                for j in range(n): #reparcourt le nombre d'exemples dans le dataset\n",
    "                    next_computed_layer[j][i] = dict_[next_computed_layer[j][i]]\n",
    "\n",
    "                link.append(dict_) #rajoute le dict des valeurs prédites 'dict_' dans une liste 'link'\n",
    "\n",
    "            list_computed.append(next_computed_layer) #rajoute la nouvelle couche dans la liste 'list_computed'\n",
    "            self.list_link.append(link) #rajoute la liste 'link' dans la liste générale 'list_link'\n",
    "            \n",
    "            if print_training_accuracy:\n",
    "                print(\"Layer = \" + str(layer) \n",
    "                      + \" | Lut count = \" + (str(self.layers[layer]) + \"    \")[:5] \n",
    "                      + \" | Training Accuracy = \" + str(self.accuracy(X_train, y_train)))\n",
    "    \n",
    "    \"\"\"\n",
    "    Prediction de la classe pour une entrée x.\n",
    "    \"\"\"\n",
    "    def one_prediction(self, x):   \n",
    "        list_computed = [x]\n",
    "\n",
    "        # Calcul couche par couche\n",
    "        for layer in range(len(self.list_link)):\n",
    "            layer_luts = self.list_luts[layer]\n",
    "            link = self.list_link[layer]\n",
    "            last_computed_layer = list_computed[-1]\n",
    "\n",
    "            next_computed_layer = []\n",
    "            for i in range(len(layer_luts)):\n",
    "                s = \"\"\n",
    "                for z in range(self.k):\n",
    "                    s += str(last_computed_layer[layer_luts[i][z]])\n",
    "                next_computed_layer.append(link[i][s])\n",
    "            list_computed.append(next_computed_layer)\n",
    "        \n",
    "        # Somme du nombre de 1 sur l'ensemble des luts de la dernière couche\n",
    "        resu = 0\n",
    "        for i in range(len(self.list_luts[len(self.list_link) - 1])):\n",
    "            resu += list_computed[-1][i]\n",
    "        \n",
    "        # Retourne 1 si il y a plus de 1 que de 0 sur l'ensemble des luts de la dernière couche (0 sinon)\n",
    "        return int(resu > len(self.list_luts[len(self.list_link) - 1]) / 2)\n",
    "    \n",
    "    \"\"\"\n",
    "    Prediction de la classe pour le vecteur X. \n",
    "    \"\"\"\n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        for x in X:\n",
    "            y.append(self.one_prediction(x))\n",
    "        return np.array(y)\n",
    "    \n",
    "    \"\"\"\n",
    "    Calcul de la précision du modèle.\n",
    "    \"\"\"\n",
    "    def accuracy(self, X, y):\n",
    "        return accuracy_score(self.predict(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expérimentations\n",
    "\n",
    "### Expérimentation n°1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = [784, 1024, 1024, 1024, 1024, 1024, 1] \n",
    "k = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Memorization(layers, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = 0 | Lut count = 784   | Training Accuracy = 0.51076\n",
      "Layer = 1 | Lut count = 1024  | Training Accuracy = 0.78768\n",
      "Layer = 2 | Lut count = 1024  | Training Accuracy = 0.84706\n",
      "Layer = 3 | Lut count = 1024  | Training Accuracy = 0.86198\n",
      "Layer = 4 | Lut count = 1024  | Training Accuracy = 0.87266\n",
      "Layer = 5 | Lut count = 1024  | Training Accuracy = 0.88226\n",
      "Layer = 6 | Lut count = 1     | Training Accuracy = 0.88486\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, print_training_accuracy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expérimentation n°2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2   | Training Accuracy = 0.621 | Test Accuracy = 0.6217\n",
      "k = 4   | Training Accuracy = 0.806 | Test Accuracy = 0.8123\n",
      "k = 6   | Training Accuracy = 0.843 | Test Accuracy = 0.8463\n",
      "k = 8   | Training Accuracy = 0.889 | Test Accuracy = 0.8748\n",
      "k = 10  | Training Accuracy = 0.945 | Test Accuracy = 0.8928\n",
      "k = 12  | Training Accuracy = 0.989 | Test Accuracy = 0.8886\n",
      "k = 14  | Training Accuracy = 0.999 | Test Accuracy = 0.8062\n",
      "k = 16  | Training Accuracy = 0.999 | Test Accuracy = 0.6382\n"
     ]
    }
   ],
   "source": [
    "for k in [2,4,6,8,10,12,14,16]:\n",
    "    model = Memorization(layers, k)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"k = \" + (str(k) + \"  \")[:3]\n",
    "          + \" | Training Accuracy = \" + (str(model.accuracy(X_train, y_train)) + \"   \")[:5] \n",
    "          + \" | Test Accuracy = \" + str(model.accuracy(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expérimentation n°3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_random = np.array([np.random.randint(2) for i in range(len(y_train))])\n",
    "y_test_random = np.array([np.random.randint(2) for i in range(len(y_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2   | Training Accuracy = 0.533 | Test Accuracy = 0.504\n",
      "k = 4   | Training Accuracy = 0.566 | Test Accuracy = 0.513\n",
      "k = 6   | Training Accuracy = 0.657 | Test Accuracy = 0.511\n",
      "k = 8   | Training Accuracy = 0.766 | Test Accuracy = 0.493\n",
      "k = 10  | Training Accuracy = 0.938 | Test Accuracy = 0.471\n",
      "k = 12  | Training Accuracy = 0.987 | Test Accuracy = 0.508\n",
      "k = 14  | Training Accuracy = 0.998 | Test Accuracy = 0.512\n",
      "k = 16  | Training Accuracy = 0.998 | Test Accuracy = 0.508\n"
     ]
    }
   ],
   "source": [
    "for k in [2,4,6,8,10,12,14,16]:\n",
    "    model = Memorization(layers, k)\n",
    "    model.fit(X_train, y_train_random)\n",
    "    print(\"k = \" + (str(k) + \"  \")[:3]\n",
    "          + \" | Training Accuracy = \" + (str(model.accuracy(X_train, y_train_random)) + \"   \")[:5] \n",
    "          + \" | Test Accuracy = \" + str(model.accuracy(X_test, y_test_random)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expérimentation n°4\n",
    "\n",
    "L'objectif de cette expérience est de comparer le modèle de mémorisation avec des méthodes standards de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test du modèle : 5-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_5 = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn_5.fit(X_train, y_train)\n",
    "knn_5_train_accuracy = accuracy_score(knn_5.predict(X_train), y_train)\n",
    "knn_5_test_accuracy = accuracy_score(knn_5.predict(X_test), y_test)\n",
    "\n",
    "list_results.append((\"5-Nearest Neighbors\", knn_5_train_accuracy, knn_5_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test du modèle : 1-Nearest Neighbors\n",
    "knn_1 = KNeighborsClassifier(n_neighbors = 1)\n",
    "knn_1.fit(X_train, y_train)\n",
    "knn_1_train_accuracy = accuracy_score(knn_1.predict(X_train), y_train)\n",
    "knn_1_test_accuracy = accuracy_score(knn_1.predict(X_test), y_test)\n",
    "\n",
    "list_results.append((\"1-Nearest Neighbors\", knn_1_train_accuracy, knn_1_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test du modèle : Random Forest (10 Trees)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_train_accuracy = accuracy_score(rf.predict(X_train), y_train)\n",
    "rf_test_accuracy = accuracy_score(rf.predict(X_test), y_test)\n",
    "\n",
    "list_results.append((\"Random Forest (10 Trees)\", rf_train_accuracy, rf_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test du modèle : Memorization\n",
    "\n",
    "memo = Memorization(layers, k)\n",
    "memo.fit(X_train, y_train)\n",
    "memo_train_accuracy = accuracy_score(memo.predict(X_train), y_train)\n",
    "memo_test_accuracy = accuracy_score(memo.predict(X_test), y_test)\n",
    "\n",
    "list_results.append((\"Memorization\", memo_train_accuracy, memo_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test du modèle : Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_train_accuracy = accuracy_score(lr.predict(X_train), y_train)\n",
    "lr_test_accuracy = accuracy_score(lr.predict(X_test), y_test)\n",
    "\n",
    "list_results.append((\"Logistic Regression\", lr_train_accuracy, lr_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test du modèle : Naïve Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_train_accuracy = accuracy_score(nb.predict(X_train), y_train)\n",
    "nb_test_accuracy = accuracy_score(nb.predict(X_test), y_test)\n",
    "\n",
    "list_results.append((\"Naïve Bayes\", nb_train_accuracy, nb_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test du modèle : Random Guess\n",
    "random_guess = lambda x : np.random.randint(2)\n",
    "rg_train_accuracy = accuracy_score([random_guess(x) for x in X_train], y_train)\n",
    "rg_test_accuracy = accuracy_score([random_guess(x) for x in X_test], y_test)\n",
    "\n",
    "\n",
    "list_results.append((\"Random Guess\", rg_train_accuracy, rg_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Nearest Neighbors      | Training Accuracy = 0.96   | Test Accuracy = 0.92\n",
      "1-Nearest Neighbors      | Training Accuracy = 1.0    | Test Accuracy = 0.93\n",
      "Random Forest (10 Trees) | Training Accuracy = 0.996  | Test Accuracy = 0.871\n",
      "Memorization             | Training Accuracy = 1.0    | Test Accuracy = 0.556\n",
      "Logistic Regression      | Training Accuracy = 0.958  | Test Accuracy = 0.809\n",
      "Naïve Bayes              | Training Accuracy = 0.666  | Test Accuracy = 0.687\n",
      "Random Guess             | Training Accuracy = 0.492  | Test Accuracy = 0.498\n"
     ]
    }
   ],
   "source": [
    "# Comparaison des modèles\n",
    "\n",
    "for name, train_acc, test_acc in list_results:\n",
    "    print((str(name) + \"             \")[:24] \n",
    "          + \" | Training Accuracy = \" + (str(train_acc) + \"   \")[:6]\n",
    "          + \" | Test Accuracy = \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expérimentation n°5\n",
    "\n",
    "L'objectif de cette expérience est d'appliquer le principe de mémorisation sur la tâche de séparation du i-ème digit de MNIST avec le j-ème digit.\n",
    "On a 10 digits différents (0 à 9) et des paires de digits. Ce qui revient à faire 2 parmi n expériences (=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2   | Training Accuracy = 0.562 | Test Accuracy = 0.573\n",
      "k = 4   | Training Accuracy = 0.659 | Test Accuracy = 0.654\n",
      "k = 6   | Training Accuracy = 0.814 | Test Accuracy = 0.755\n",
      "k = 8   | Training Accuracy = 0.938 | Test Accuracy = 0.738\n",
      "k = 10  | Training Accuracy = 0.985 | Test Accuracy = 0.709\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.692\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.542\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.523\n"
     ]
    }
   ],
   "source": [
    "for k in [2,4,6,8,10,12,14,16]:\n",
    "    model = Memorization(layers, k)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"k = \" + (str(k) + \"  \")[:3]\n",
    "          + \" | Training Accuracy = \" + (str(model.accuracy(X_train, y_train)) + \"   \")[:5] \n",
    "          + \" | Test Accuracy = \" + str(model.accuracy(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnistfile =\"mnist.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "import dataset_loader\n",
    "train_set, valid_set, test_set = dataset_loader.load_mnist(mnistfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Limitation de la taille du jeu de données pour réduire le temps de calcul (A retirer)\n",
    "train_set[0] = train_set[0][:1000]\n",
    "train_set[1] = train_set[1][:1000]\n",
    "valid_set[0] = valid_set[0][:1000]\n",
    "valid_set[1] = valid_set[1][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Binarisation du dataset\n",
    "for i in range (train_set[0].shape[0]):\n",
    "    train_set[0][i]=binarise(train_set[0][i])\n",
    "\n",
    "for i in range (valid_set[0].shape[0]):\n",
    "    valid_set[0][i]=binarise(valid_set[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pairwise_dataset(digit_i, digit_j, train_set, valid_set):\n",
    "    \"\"\"train set\"\"\"\n",
    "    #train set (digit i et digit j)\n",
    "    digit_i_train_idx = np.where(train_set[1]==digit_i)\n",
    "    digit_j_train_idx = np.where(train_set[1]==digit_j)\n",
    "    pairwise_train_idx = np.concatenate((digit_i_train_idx, digit_j_train_idx), axis=1)\n",
    "    \n",
    "    train_X, train_y = train_set[0][tuple(pairwise_train_idx)].astype(int), train_set[1][tuple(pairwise_train_idx)]\n",
    "    \n",
    "    #transform labels of digit i and digit j into 1 and 0\n",
    "    #digit_i = 1 by default\n",
    "    train_y = (train_y == digit_i).astype(int)\n",
    "    \n",
    "    #shuffle\n",
    "    train_perm = np.random.permutation(train_X.shape[0])\n",
    "    new_train_set = [train_X[train_perm,:], train_y[train_perm]]\n",
    "    \n",
    "    \"\"\"test set\"\"\"\n",
    "    #test set (digit i et digit j)\n",
    "    digit_i_val_idx = np.where(valid_set[1]==digit_i)\n",
    "    digit_j_val_idx = np.where(valid_set[1]==digit_j)\n",
    "    pairwise_val_idx = np.concatenate((digit_i_val_idx, digit_j_val_idx), axis=1)\n",
    "    \n",
    "    test_X, test_y = valid_set[0][tuple(pairwise_val_idx)].astype(int), valid_set[1][tuple(pairwise_val_idx)]\n",
    "\n",
    "    #transform labels of digit i and digit j into 1 and 0\n",
    "    #digit_i = 1 by default\n",
    "    test_y = (test_y == digit_i).astype(int)\n",
    "    \n",
    "    \n",
    "    #shuffle\n",
    "    test_perm = np.random.permutation(test_X.shape[0])\n",
    "    new_test_set = [test_X[test_perm,:], test_y[test_perm]]\n",
    "    \n",
    "    return new_train_set, new_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i-th digit: 0, j-th digit: 1\n",
      "k = 2   | Training Accuracy = 0.935 | Test Accuracy = 0.953\n",
      "k = 4   | Training Accuracy = 0.985 | Test Accuracy = 0.958\n",
      "k = 6   | Training Accuracy = 1.0   | Test Accuracy = 0.958\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.793\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.747\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.721\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.675\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.664\n",
      "i-th digit: 0, j-th digit: 2\n",
      "k = 2   | Training Accuracy = 0.700 | Test Accuracy = 0.641\n",
      "k = 4   | Training Accuracy = 0.898 | Test Accuracy = 0.856\n",
      "k = 6   | Training Accuracy = 0.994 | Test Accuracy = 0.918\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.760\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.617\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.545\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.578\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.497\n",
      "i-th digit: 0, j-th digit: 3\n",
      "k = 2   | Training Accuracy = 0.813 | Test Accuracy = 0.793\n",
      "k = 4   | Training Accuracy = 0.896 | Test Accuracy = 0.835\n",
      "k = 6   | Training Accuracy = 0.989 | Test Accuracy = 0.943\n",
      "k = 8   | Training Accuracy = 0.994 | Test Accuracy = 0.788\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.737\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.596\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.544\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.497\n",
      "i-th digit: 0, j-th digit: 4\n",
      "k = 2   | Training Accuracy = 0.773 | Test Accuracy = 0.741\n",
      "k = 4   | Training Accuracy = 0.939 | Test Accuracy = 0.940\n",
      "k = 6   | Training Accuracy = 0.994 | Test Accuracy = 0.930\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.844\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.650\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.462\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.5\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.510\n",
      "i-th digit: 0, j-th digit: 5\n",
      "k = 2   | Training Accuracy = 0.748 | Test Accuracy = 0.787\n",
      "k = 4   | Training Accuracy = 0.938 | Test Accuracy = 0.842\n",
      "k = 6   | Training Accuracy = 0.983 | Test Accuracy = 0.921\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.768\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.564\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.509\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.564\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.518\n",
      "i-th digit: 0, j-th digit: 6\n",
      "k = 2   | Training Accuracy = 0.717 | Test Accuracy = 0.701\n",
      "k = 4   | Training Accuracy = 0.943 | Test Accuracy = 0.889\n",
      "k = 6   | Training Accuracy = 1.0   | Test Accuracy = 0.860\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.75\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.692\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.572\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.490\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.552\n",
      "i-th digit: 0, j-th digit: 7\n",
      "k = 2   | Training Accuracy = 0.751 | Test Accuracy = 0.774\n",
      "k = 4   | Training Accuracy = 0.956 | Test Accuracy = 0.926\n",
      "k = 6   | Training Accuracy = 1.0   | Test Accuracy = 0.870\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.806\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.695\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.626\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.539\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.603\n",
      "i-th digit: 0, j-th digit: 8\n",
      "k = 2   | Training Accuracy = 0.673 | Test Accuracy = 0.666\n",
      "k = 4   | Training Accuracy = 0.926 | Test Accuracy = 0.851\n",
      "k = 6   | Training Accuracy = 1.0   | Test Accuracy = 0.958\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.723\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.707\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.553\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.543\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.451\n",
      "i-th digit: 0, j-th digit: 9\n",
      "k = 2   | Training Accuracy = 0.756 | Test Accuracy = 0.661\n",
      "k = 4   | Training Accuracy = 0.944 | Test Accuracy = 0.928\n",
      "k = 6   | Training Accuracy = 0.972 | Test Accuracy = 0.957\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.861\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.771\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.633\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.652\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.523\n",
      "i-th digit: 1, j-th digit: 2\n",
      "k = 2   | Training Accuracy = 0.698 | Test Accuracy = 0.607\n",
      "k = 4   | Training Accuracy = 0.959 | Test Accuracy = 0.931\n",
      "k = 6   | Training Accuracy = 0.984 | Test Accuracy = 0.884\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.853\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.696\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.664\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.670\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.649\n",
      "i-th digit: 1, j-th digit: 3\n",
      "k = 2   | Training Accuracy = 0.711 | Test Accuracy = 0.707\n",
      "k = 4   | Training Accuracy = 0.939 | Test Accuracy = 0.933\n",
      "k = 6   | Training Accuracy = 1.0   | Test Accuracy = 0.897\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.830\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.702\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.620\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.641\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.533\n",
      "i-th digit: 1, j-th digit: 4\n",
      "k = 2   | Training Accuracy = 0.758 | Test Accuracy = 0.797\n",
      "k = 4   | Training Accuracy = 0.950 | Test Accuracy = 0.940\n",
      "k = 6   | Training Accuracy = 0.995 | Test Accuracy = 0.886\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.880\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.708\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.684\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.714\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.607\n",
      "i-th digit: 1, j-th digit: 5\n",
      "k = 2   | Training Accuracy = 0.910 | Test Accuracy = 0.914\n",
      "k = 4   | Training Accuracy = 0.970 | Test Accuracy = 0.934\n",
      "k = 6   | Training Accuracy = 1.0   | Test Accuracy = 0.914\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.747\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.727\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.671\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.590\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.611\n",
      "i-th digit: 1, j-th digit: 6\n",
      "k = 2   | Training Accuracy = 0.631 | Test Accuracy = 0.668\n",
      "k = 4   | Training Accuracy = 0.967 | Test Accuracy = 0.973\n",
      "k = 6   | Training Accuracy = 0.995 | Test Accuracy = 0.931\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.763\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.663\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.773\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.642\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.647\n",
      "i-th digit: 1, j-th digit: 7\n",
      "k = 2   | Training Accuracy = 0.763 | Test Accuracy = 0.668\n",
      "k = 4   | Training Accuracy = 0.937 | Test Accuracy = 0.894\n",
      "k = 6   | Training Accuracy = 1.0   | Test Accuracy = 0.929\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.894\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.793\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.688\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.597\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.623\n",
      "i-th digit: 1, j-th digit: 8\n",
      "k = 2   | Training Accuracy = 0.669 | Test Accuracy = 0.700\n",
      "k = 4   | Training Accuracy = 0.910 | Test Accuracy = 0.903\n",
      "k = 6   | Training Accuracy = 0.995 | Test Accuracy = 0.920\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.858\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.785\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.728\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.615\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.649\n",
      "i-th digit: 1, j-th digit: 9\n",
      "k = 2   | Training Accuracy = 0.912 | Test Accuracy = 0.942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 4   | Training Accuracy = 0.887 | Test Accuracy = 0.911\n",
      "k = 6   | Training Accuracy = 1.0   | Test Accuracy = 0.973\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.947\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.682\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.687\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.656\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.567\n",
      "i-th digit: 2, j-th digit: 3\n",
      "k = 2   | Training Accuracy = 0.652 | Test Accuracy = 0.709\n",
      "k = 4   | Training Accuracy = 0.942 | Test Accuracy = 0.876\n",
      "k = 6   | Training Accuracy = 0.957 | Test Accuracy = 0.876\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.804\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.623\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.571\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.542\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.528\n",
      "i-th digit: 2, j-th digit: 4\n",
      "k = 2   | Training Accuracy = 0.606 | Test Accuracy = 0.606\n",
      "k = 4   | Training Accuracy = 0.932 | Test Accuracy = 0.896\n",
      "k = 6   | Training Accuracy = 0.988 | Test Accuracy = 0.907\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.748\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.633\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.497\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.530\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.530\n",
      "i-th digit: 2, j-th digit: 5\n",
      "k = 2   | Training Accuracy = 0.744 | Test Accuracy = 0.685\n",
      "k = 4   | Training Accuracy = 0.886 | Test Accuracy = 0.901\n",
      "k = 6   | Training Accuracy = 1.0   | Test Accuracy = 0.845\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.760\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.558\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.558\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.488\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.488\n",
      "i-th digit: 2, j-th digit: 6\n",
      "k = 2   | Training Accuracy = 0.822 | Test Accuracy = 0.785\n",
      "k = 4   | Training Accuracy = 0.859 | Test Accuracy = 0.741\n",
      "k = 6   | Training Accuracy = 0.984 | Test Accuracy = 0.804\n",
      "k = 8   | Training Accuracy = 0.989 | Test Accuracy = 0.765\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.585\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.512\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.497\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.482\n",
      "i-th digit: 2, j-th digit: 7\n",
      "k = 2   | Training Accuracy = 0.664 | Test Accuracy = 0.654\n",
      "k = 4   | Training Accuracy = 0.917 | Test Accuracy = 0.878\n",
      "k = 6   | Training Accuracy = 0.994 | Test Accuracy = 0.929\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.827\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.686\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.616\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.528\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.588\n",
      "i-th digit: 2, j-th digit: 8\n",
      "k = 2   | Training Accuracy = 0.652 | Test Accuracy = 0.630\n",
      "k = 4   | Training Accuracy = 0.855 | Test Accuracy = 0.828\n",
      "k = 6   | Training Accuracy = 0.978 | Test Accuracy = 0.911\n",
      "k = 8   | Training Accuracy = 0.994 | Test Accuracy = 0.744\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.645\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.494\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.489\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.505\n",
      "i-th digit: 2, j-th digit: 9\n",
      "k = 2   | Training Accuracy = 0.744 | Test Accuracy = 0.743\n",
      "k = 4   | Training Accuracy = 0.879 | Test Accuracy = 0.874\n",
      "k = 6   | Training Accuracy = 0.976 | Test Accuracy = 0.937\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.869\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.753\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.618\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.570\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.550\n",
      "i-th digit: 3, j-th digit: 4\n",
      "k = 2   | Training Accuracy = 0.726 | Test Accuracy = 0.737\n",
      "k = 4   | Training Accuracy = 0.845 | Test Accuracy = 0.877\n",
      "k = 6   | Training Accuracy = 0.984 | Test Accuracy = 0.871\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.834\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.647\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.561\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.529\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.598\n",
      "i-th digit: 3, j-th digit: 5\n",
      "k = 2   | Training Accuracy = 0.614 | Test Accuracy = 0.603\n",
      "k = 4   | Training Accuracy = 0.828 | Test Accuracy = 0.764\n",
      "k = 6   | Training Accuracy = 0.953 | Test Accuracy = 0.806\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.746\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.645\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.497\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.447\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.529\n",
      "i-th digit: 3, j-th digit: 6\n",
      "k = 2   | Training Accuracy = 0.831 | Test Accuracy = 0.813\n",
      "k = 4   | Training Accuracy = 0.942 | Test Accuracy = 0.933\n",
      "k = 6   | Training Accuracy = 0.985 | Test Accuracy = 0.875\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.885\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.684\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.578\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.531\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.540\n",
      "i-th digit: 3, j-th digit: 7\n",
      "k = 2   | Training Accuracy = 0.727 | Test Accuracy = 0.701\n",
      "k = 4   | Training Accuracy = 0.934 | Test Accuracy = 0.908\n",
      "k = 6   | Training Accuracy = 0.964 | Test Accuracy = 0.894\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.743\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.660\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.504\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.495\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.504\n",
      "i-th digit: 3, j-th digit: 8\n",
      "k = 2   | Training Accuracy = 0.507 | Test Accuracy = 0.545\n",
      "k = 4   | Training Accuracy = 0.871 | Test Accuracy = 0.831\n",
      "k = 6   | Training Accuracy = 0.940 | Test Accuracy = 0.775\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.729\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.622\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.525\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.535\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.5\n",
      "i-th digit: 3, j-th digit: 9\n",
      "k = 2   | Training Accuracy = 0.683 | Test Accuracy = 0.682\n",
      "k = 4   | Training Accuracy = 0.870 | Test Accuracy = 0.853\n",
      "k = 6   | Training Accuracy = 0.987 | Test Accuracy = 0.952\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.862\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.677\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.606\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.535\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.507\n",
      "i-th digit: 4, j-th digit: 5\n",
      "k = 2   | Training Accuracy = 0.733 | Test Accuracy = 0.763\n",
      "k = 4   | Training Accuracy = 0.833 | Test Accuracy = 0.878\n",
      "k = 6   | Training Accuracy = 1.0   | Test Accuracy = 0.810\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.742\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.626\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.521\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.557\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.505\n",
      "i-th digit: 4, j-th digit: 6\n",
      "k = 2   | Training Accuracy = 0.673 | Test Accuracy = 0.549\n",
      "k = 4   | Training Accuracy = 0.862 | Test Accuracy = 0.741\n",
      "k = 6   | Training Accuracy = 0.974 | Test Accuracy = 0.884\n",
      "k = 8   | Training Accuracy = 0.994 | Test Accuracy = 0.857\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.565\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.565\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.494\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.483\n",
      "i-th digit: 4, j-th digit: 7\n",
      "k = 2   | Training Accuracy = 0.666 | Test Accuracy = 0.617\n",
      "k = 4   | Training Accuracy = 0.833 | Test Accuracy = 0.821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 6   | Training Accuracy = 0.940 | Test Accuracy = 0.926\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.738\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.628\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.544\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.492\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.492\n",
      "i-th digit: 4, j-th digit: 8\n",
      "k = 2   | Training Accuracy = 0.774 | Test Accuracy = 0.816\n",
      "k = 4   | Training Accuracy = 0.910 | Test Accuracy = 0.857\n",
      "k = 6   | Training Accuracy = 0.979 | Test Accuracy = 0.893\n",
      "k = 8   | Training Accuracy = 0.994 | Test Accuracy = 0.834\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.615\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.420\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.526\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.467\n",
      "i-th digit: 4, j-th digit: 9\n",
      "k = 2   | Training Accuracy = 0.643 | Test Accuracy = 0.619\n",
      "k = 4   | Training Accuracy = 0.757 | Test Accuracy = 0.684\n",
      "k = 6   | Training Accuracy = 0.840 | Test Accuracy = 0.641\n",
      "k = 8   | Training Accuracy = 0.977 | Test Accuracy = 0.804\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.663\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.597\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.565\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.478\n",
      "i-th digit: 5, j-th digit: 6\n",
      "k = 2   | Training Accuracy = 0.757 | Test Accuracy = 0.745\n",
      "k = 4   | Training Accuracy = 0.840 | Test Accuracy = 0.787\n",
      "k = 6   | Training Accuracy = 0.989 | Test Accuracy = 0.849\n",
      "k = 8   | Training Accuracy = 0.994 | Test Accuracy = 0.773\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.627\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.580\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.542\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.462\n",
      "i-th digit: 5, j-th digit: 7\n",
      "k = 2   | Training Accuracy = 0.809 | Test Accuracy = 0.819\n",
      "k = 4   | Training Accuracy = 0.885 | Test Accuracy = 0.837\n",
      "k = 6   | Training Accuracy = 0.989 | Test Accuracy = 0.882\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.782\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.651\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.556\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.488\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.538\n",
      "i-th digit: 5, j-th digit: 8\n",
      "k = 2   | Training Accuracy = 0.735 | Test Accuracy = 0.673\n",
      "k = 4   | Training Accuracy = 0.857 | Test Accuracy = 0.854\n",
      "k = 6   | Training Accuracy = 0.973 | Test Accuracy = 0.798\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.768\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.577\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.492\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.562\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.472\n",
      "i-th digit: 5, j-th digit: 9\n",
      "k = 2   | Training Accuracy = 0.682 | Test Accuracy = 0.630\n",
      "k = 4   | Training Accuracy = 0.898 | Test Accuracy = 0.920\n",
      "k = 6   | Training Accuracy = 0.963 | Test Accuracy = 0.864\n",
      "k = 8   | Training Accuracy = 0.995 | Test Accuracy = 0.817\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.668\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.584\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.570\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.518\n",
      "i-th digit: 6, j-th digit: 7\n",
      "k = 2   | Training Accuracy = 0.785 | Test Accuracy = 0.845\n",
      "k = 4   | Training Accuracy = 0.935 | Test Accuracy = 0.924\n",
      "k = 6   | Training Accuracy = 1.0   | Test Accuracy = 0.924\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.859\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.704\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.539\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.596\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.492\n",
      "i-th digit: 6, j-th digit: 8\n",
      "k = 2   | Training Accuracy = 0.843 | Test Accuracy = 0.858\n",
      "k = 4   | Training Accuracy = 0.907 | Test Accuracy = 0.821\n",
      "k = 6   | Training Accuracy = 0.995 | Test Accuracy = 0.916\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.738\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.659\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.528\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.513\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.486\n",
      "i-th digit: 6, j-th digit: 9\n",
      "k = 2   | Training Accuracy = 0.703 | Test Accuracy = 0.708\n",
      "k = 4   | Training Accuracy = 0.918 | Test Accuracy = 0.912\n",
      "k = 6   | Training Accuracy = 0.978 | Test Accuracy = 0.912\n",
      "k = 8   | Training Accuracy = 0.995 | Test Accuracy = 0.873\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.752\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.626\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.572\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.548\n",
      "i-th digit: 7, j-th digit: 8\n",
      "k = 2   | Training Accuracy = 0.615 | Test Accuracy = 0.65\n",
      "k = 4   | Training Accuracy = 0.948 | Test Accuracy = 0.87\n",
      "k = 6   | Training Accuracy = 0.989 | Test Accuracy = 0.88\n",
      "k = 8   | Training Accuracy = 1.0   | Test Accuracy = 0.835\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.575\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.635\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.495\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.475\n",
      "i-th digit: 7, j-th digit: 9\n",
      "k = 2   | Training Accuracy = 0.582 | Test Accuracy = 0.506\n",
      "k = 4   | Training Accuracy = 0.798 | Test Accuracy = 0.720\n",
      "k = 6   | Training Accuracy = 0.941 | Test Accuracy = 0.767\n",
      "k = 8   | Training Accuracy = 0.991 | Test Accuracy = 0.711\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.6\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.627\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.479\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.488\n",
      "i-th digit: 8, j-th digit: 9\n",
      "k = 2   | Training Accuracy = 0.574 | Test Accuracy = 0.611\n",
      "k = 4   | Training Accuracy = 0.881 | Test Accuracy = 0.834\n",
      "k = 6   | Training Accuracy = 0.969 | Test Accuracy = 0.787\n",
      "k = 8   | Training Accuracy = 0.991 | Test Accuracy = 0.870\n",
      "k = 10  | Training Accuracy = 1.0   | Test Accuracy = 0.637\n",
      "k = 12  | Training Accuracy = 1.0   | Test Accuracy = 0.512\n",
      "k = 14  | Training Accuracy = 1.0   | Test Accuracy = 0.569\n",
      "k = 16  | Training Accuracy = 1.0   | Test Accuracy = 0.481\n"
     ]
    }
   ],
   "source": [
    "pairwise_matrix=np.identity(10)\n",
    "\n",
    "k_list=[]\n",
    "train_acc_list=[]\n",
    "test_acc_list=[]\n",
    "        \n",
    "for digit_i in range(pairwise_matrix.shape[0]):\n",
    "    for digit_j in range(pairwise_matrix.shape[1]):\n",
    "        if pairwise_matrix[digit_i, digit_j]==0:\n",
    "            new_train_set, new_test_set = create_pairwise_dataset(digit_i, digit_j, train_set, valid_set)\n",
    "            X_train, y_train = new_train_set[0], new_train_set[1]\n",
    "            X_test, y_test = new_test_set[0], new_test_set[1]\n",
    "            \n",
    "            #uptade conditions\n",
    "            pairwise_matrix[digit_i, digit_j]=1\n",
    "            pairwise_matrix[digit_j, digit_i]=1\n",
    "\n",
    "            #calculate for each dataset and each k, training and test accuracy\n",
    "            print('i-th digit: {a}, j-th digit: {b}'.format(a=digit_i, b=digit_j))\n",
    "            for k in [2,4,6,8,10,12,14,16]:\n",
    "                model = Memorization(layers, k)\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                train_acc = model.accuracy(X_train, y_train)\n",
    "                test_acc = model.accuracy(X_test, y_test)\n",
    "                \n",
    "                k_list.append(k)\n",
    "                train_acc_list.append(train_acc)\n",
    "                test_acc_list.append(test_acc)\n",
    "                \n",
    "                print(\"k = \" + (str(k) + \"  \")[:3]\n",
    "          + \" | Training Accuracy = \" + (str(train_acc) + \"   \")[:5] \n",
    "          + \" | Test Accuracy = \" + str(test_acc)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display graph\n",
    "plt.plot(k_list, train_acc_list, 'b+', label='training')\n",
    "plt.plot(k_list,test_acc_list, 'r+', label='test')\n",
    "plt.title('45×8 pairs of training and test accuracies as a function of the size of the lookup table (k) for Pairwise-MNIST')\n",
    "plt.legend()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(0,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expérimentation n°6\n",
    "\n",
    "L'objectif de l'expérience est de reproduire l'expérience 5 en gardant k=2 et en faisant varier le nombre de couches (de 2^0 à 2^5). Chaque couche à 1024 luts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i-th digit: 0, j-th digit: 1\n",
      "d = 0   | Training Accuracy = 0.554 | Test Accuracy = 0.484\n",
      "d = 1   | Training Accuracy = 0.738 | Test Accuracy = 0.666\n",
      "d = 2   | Training Accuracy = 0.554 | Test Accuracy = 0.484\n",
      "d = 3   | Training Accuracy = 0.769 | Test Accuracy = 0.777\n",
      "d = 4   | Training Accuracy = 0.874 | Test Accuracy = 0.866\n",
      "d = 5   | Training Accuracy = 0.910 | Test Accuracy = 0.96\n",
      "i-th digit: 0, j-th digit: 2\n",
      "d = 0   | Training Accuracy = 0.519 | Test Accuracy = 0.598\n",
      "d = 1   | Training Accuracy = 0.524 | Test Accuracy = 0.604\n",
      "d = 2   | Training Accuracy = 0.730 | Test Accuracy = 0.725\n",
      "d = 3   | Training Accuracy = 0.789 | Test Accuracy = 0.791\n",
      "d = 4   | Training Accuracy = 0.740 | Test Accuracy = 0.741\n",
      "d = 5   | Training Accuracy = 0.808 | Test Accuracy = 0.791\n",
      "i-th digit: 0, j-th digit: 3\n",
      "d = 0   | Training Accuracy = 0.741 | Test Accuracy = 0.810\n",
      "d = 1   | Training Accuracy = 0.732 | Test Accuracy = 0.759\n",
      "d = 2   | Training Accuracy = 0.741 | Test Accuracy = 0.810\n",
      "d = 3   | Training Accuracy = 0.816 | Test Accuracy = 0.851\n",
      "d = 4   | Training Accuracy = 0.854 | Test Accuracy = 0.847\n",
      "d = 5   | Training Accuracy = 0.882 | Test Accuracy = 0.888\n",
      "i-th digit: 0, j-th digit: 4\n",
      "d = 0   | Training Accuracy = 0.751 | Test Accuracy = 0.696\n",
      "d = 1   | Training Accuracy = 0.552 | Test Accuracy = 0.545\n",
      "d = 2   | Training Accuracy = 0.714 | Test Accuracy = 0.739\n",
      "d = 3   | Training Accuracy = 0.829 | Test Accuracy = 0.867\n",
      "d = 4   | Training Accuracy = 0.866 | Test Accuracy = 0.829\n",
      "d = 5   | Training Accuracy = 0.894 | Test Accuracy = 0.895\n",
      "i-th digit: 0, j-th digit: 5\n",
      "d = 0   | Training Accuracy = 0.603 | Test Accuracy = 0.713\n",
      "d = 1   | Training Accuracy = 0.788 | Test Accuracy = 0.686\n",
      "d = 2   | Training Accuracy = 0.653 | Test Accuracy = 0.594\n",
      "d = 3   | Training Accuracy = 0.763 | Test Accuracy = 0.745\n",
      "d = 4   | Training Accuracy = 0.929 | Test Accuracy = 0.891\n",
      "d = 5   | Training Accuracy = 0.793 | Test Accuracy = 0.816\n",
      "i-th digit: 0, j-th digit: 6\n",
      "d = 0   | Training Accuracy = 0.611 | Test Accuracy = 0.685\n",
      "d = 1   | Training Accuracy = 0.781 | Test Accuracy = 0.790\n",
      "d = 2   | Training Accuracy = 0.796 | Test Accuracy = 0.8\n",
      "d = 3   | Training Accuracy = 0.786 | Test Accuracy = 0.757\n",
      "d = 4   | Training Accuracy = 0.840 | Test Accuracy = 0.790\n",
      "d = 5   | Training Accuracy = 0.895 | Test Accuracy = 0.9\n",
      "i-th digit: 0, j-th digit: 7\n",
      "d = 0   | Training Accuracy = 0.734 | Test Accuracy = 0.693\n",
      "d = 1   | Training Accuracy = 0.756 | Test Accuracy = 0.736\n",
      "d = 2   | Training Accuracy = 0.788 | Test Accuracy = 0.799\n",
      "d = 3   | Training Accuracy = 0.891 | Test Accuracy = 0.837\n",
      "d = 4   | Training Accuracy = 0.878 | Test Accuracy = 0.784\n",
      "d = 5   | Training Accuracy = 0.855 | Test Accuracy = 0.813\n",
      "i-th digit: 0, j-th digit: 8\n",
      "d = 0   | Training Accuracy = 0.722 | Test Accuracy = 0.689\n",
      "d = 1   | Training Accuracy = 0.651 | Test Accuracy = 0.635\n",
      "d = 2   | Training Accuracy = 0.545 | Test Accuracy = 0.490\n",
      "d = 3   | Training Accuracy = 0.712 | Test Accuracy = 0.671\n",
      "d = 4   | Training Accuracy = 0.823 | Test Accuracy = 0.801\n",
      "d = 5   | Training Accuracy = 0.934 | Test Accuracy = 0.900\n",
      "i-th digit: 0, j-th digit: 9\n",
      "d = 0   | Training Accuracy = 0.610 | Test Accuracy = 0.575\n",
      "d = 1   | Training Accuracy = 0.527 | Test Accuracy = 0.518\n",
      "d = 2   | Training Accuracy = 0.886 | Test Accuracy = 0.830\n",
      "d = 3   | Training Accuracy = 0.896 | Test Accuracy = 0.896\n",
      "d = 4   | Training Accuracy = 0.768 | Test Accuracy = 0.735\n",
      "d = 5   | Training Accuracy = 0.871 | Test Accuracy = 0.844\n",
      "i-th digit: 1, j-th digit: 2\n",
      "d = 0   | Training Accuracy = 0.535 | Test Accuracy = 0.386\n",
      "d = 1   | Training Accuracy = 0.814 | Test Accuracy = 0.920\n",
      "d = 2   | Training Accuracy = 0.683 | Test Accuracy = 0.735\n",
      "d = 3   | Training Accuracy = 0.803 | Test Accuracy = 0.841\n",
      "d = 4   | Training Accuracy = 0.781 | Test Accuracy = 0.772\n",
      "d = 5   | Training Accuracy = 0.961 | Test Accuracy = 0.925\n",
      "i-th digit: 1, j-th digit: 3\n",
      "d = 0   | Training Accuracy = 0.671 | Test Accuracy = 0.730\n",
      "d = 1   | Training Accuracy = 0.770 | Test Accuracy = 0.744\n",
      "d = 2   | Training Accuracy = 0.843 | Test Accuracy = 0.807\n",
      "d = 3   | Training Accuracy = 0.651 | Test Accuracy = 0.695\n",
      "d = 4   | Training Accuracy = 0.744 | Test Accuracy = 0.780\n",
      "d = 5   | Training Accuracy = 0.812 | Test Accuracy = 0.789\n",
      "i-th digit: 1, j-th digit: 4\n",
      "d = 0   | Training Accuracy = 0.566 | Test Accuracy = 0.467\n",
      "d = 1   | Training Accuracy = 0.709 | Test Accuracy = 0.701\n",
      "d = 2   | Training Accuracy = 0.770 | Test Accuracy = 0.839\n",
      "d = 3   | Training Accuracy = 0.903 | Test Accuracy = 0.917\n",
      "d = 4   | Training Accuracy = 0.923 | Test Accuracy = 0.931\n",
      "d = 5   | Training Accuracy = 0.933 | Test Accuracy = 0.917\n",
      "i-th digit: 1, j-th digit: 5\n",
      "d = 0   | Training Accuracy = 0.522 | Test Accuracy = 0.390\n",
      "d = 1   | Training Accuracy = 0.533 | Test Accuracy = 0.671\n",
      "d = 2   | Training Accuracy = 0.741 | Test Accuracy = 0.859\n",
      "d = 3   | Training Accuracy = 0.578 | Test Accuracy = 0.640\n",
      "d = 4   | Training Accuracy = 0.915 | Test Accuracy = 0.895\n",
      "d = 5   | Training Accuracy = 0.859 | Test Accuracy = 0.802\n",
      "i-th digit: 1, j-th digit: 6\n",
      "d = 0   | Training Accuracy = 0.527 | Test Accuracy = 0.465\n",
      "d = 1   | Training Accuracy = 0.527 | Test Accuracy = 0.465\n",
      "d = 2   | Training Accuracy = 0.8   | Test Accuracy = 0.834\n",
      "d = 3   | Training Accuracy = 0.833 | Test Accuracy = 0.792\n",
      "d = 4   | Training Accuracy = 0.872 | Test Accuracy = 0.926\n",
      "d = 5   | Training Accuracy = 0.9   | Test Accuracy = 0.944\n",
      "i-th digit: 1, j-th digit: 7\n",
      "d = 0   | Training Accuracy = 0.577 | Test Accuracy = 0.462\n",
      "d = 1   | Training Accuracy = 0.681 | Test Accuracy = 0.675\n",
      "d = 2   | Training Accuracy = 0.820 | Test Accuracy = 0.851\n",
      "d = 3   | Training Accuracy = 0.791 | Test Accuracy = 0.782\n",
      "d = 4   | Training Accuracy = 0.900 | Test Accuracy = 0.861\n",
      "d = 5   | Training Accuracy = 0.985 | Test Accuracy = 0.962\n",
      "i-th digit: 1, j-th digit: 8\n",
      "d = 0   | Training Accuracy = 0.638 | Test Accuracy = 0.641\n",
      "d = 1   | Training Accuracy = 0.519 | Test Accuracy = 0.493\n",
      "d = 2   | Training Accuracy = 0.700 | Test Accuracy = 0.764\n",
      "d = 3   | Training Accuracy = 0.717 | Test Accuracy = 0.689\n",
      "d = 4   | Training Accuracy = 0.757 | Test Accuracy = 0.764\n",
      "d = 5   | Training Accuracy = 0.802 | Test Accuracy = 0.820\n",
      "i-th digit: 1, j-th digit: 9\n",
      "d = 0   | Training Accuracy = 0.532 | Test Accuracy = 0.470\n",
      "d = 1   | Training Accuracy = 0.692 | Test Accuracy = 0.607\n",
      "d = 2   | Training Accuracy = 0.620 | Test Accuracy = 0.684\n",
      "d = 3   | Training Accuracy = 0.884 | Test Accuracy = 0.931\n",
      "d = 4   | Training Accuracy = 0.736 | Test Accuracy = 0.748\n",
      "d = 5   | Training Accuracy = 0.928 | Test Accuracy = 0.972\n",
      "i-th digit: 2, j-th digit: 3\n",
      "d = 0   | Training Accuracy = 0.546 | Test Accuracy = 0.472\n",
      "d = 1   | Training Accuracy = 0.829 | Test Accuracy = 0.855\n",
      "d = 2   | Training Accuracy = 0.873 | Test Accuracy = 0.861\n",
      "d = 3   | Training Accuracy = 0.795 | Test Accuracy = 0.872\n",
      "d = 4   | Training Accuracy = 0.843 | Test Accuracy = 0.861\n",
      "d = 5   | Training Accuracy = 0.863 | Test Accuracy = 0.883\n",
      "i-th digit: 2, j-th digit: 4\n",
      "d = 0   | Training Accuracy = 0.531 | Test Accuracy = 0.582\n",
      "d = 1   | Training Accuracy = 0.578 | Test Accuracy = 0.634\n",
      "d = 2   | Training Accuracy = 0.665 | Test Accuracy = 0.611\n",
      "d = 3   | Training Accuracy = 0.755 | Test Accuracy = 0.777\n",
      "d = 4   | Training Accuracy = 0.751 | Test Accuracy = 0.765\n",
      "d = 5   | Training Accuracy = 0.818 | Test Accuracy = 0.845\n",
      "i-th digit: 2, j-th digit: 5\n",
      "d = 0   | Training Accuracy = 0.581 | Test Accuracy = 0.530\n",
      "d = 1   | Training Accuracy = 0.685 | Test Accuracy = 0.697\n",
      "d = 2   | Training Accuracy = 0.691 | Test Accuracy = 0.744\n",
      "d = 3   | Training Accuracy = 0.790 | Test Accuracy = 0.852\n",
      "d = 4   | Training Accuracy = 0.790 | Test Accuracy = 0.785\n",
      "d = 5   | Training Accuracy = 0.842 | Test Accuracy = 0.791\n",
      "i-th digit: 2, j-th digit: 6\n",
      "d = 0   | Training Accuracy = 0.554 | Test Accuracy = 0.477\n",
      "d = 1   | Training Accuracy = 0.611 | Test Accuracy = 0.649\n",
      "d = 2   | Training Accuracy = 0.761 | Test Accuracy = 0.724\n",
      "d = 3   | Training Accuracy = 0.803 | Test Accuracy = 0.770\n",
      "d = 4   | Training Accuracy = 0.761 | Test Accuracy = 0.781\n",
      "d = 5   | Training Accuracy = 0.761 | Test Accuracy = 0.764\n",
      "i-th digit: 2, j-th digit: 7\n",
      "d = 0   | Training Accuracy = 0.658 | Test Accuracy = 0.676\n",
      "d = 1   | Training Accuracy = 0.728 | Test Accuracy = 0.699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d = 2   | Training Accuracy = 0.700 | Test Accuracy = 0.670\n",
      "d = 3   | Training Accuracy = 0.710 | Test Accuracy = 0.676\n",
      "d = 4   | Training Accuracy = 0.906 | Test Accuracy = 0.820\n",
      "d = 5   | Training Accuracy = 0.845 | Test Accuracy = 0.751\n",
      "i-th digit: 2, j-th digit: 8\n",
      "d = 0   | Training Accuracy = 0.615 | Test Accuracy = 0.559\n",
      "d = 1   | Training Accuracy = 0.694 | Test Accuracy = 0.672\n",
      "d = 2   | Training Accuracy = 0.763 | Test Accuracy = 0.698\n",
      "d = 3   | Training Accuracy = 0.721 | Test Accuracy = 0.768\n",
      "d = 4   | Training Accuracy = 0.736 | Test Accuracy = 0.720\n",
      "d = 5   | Training Accuracy = 0.757 | Test Accuracy = 0.672\n",
      "i-th digit: 2, j-th digit: 9\n",
      "d = 0   | Training Accuracy = 0.702 | Test Accuracy = 0.630\n",
      "d = 1   | Training Accuracy = 0.738 | Test Accuracy = 0.767\n",
      "d = 2   | Training Accuracy = 0.789 | Test Accuracy = 0.710\n",
      "d = 3   | Training Accuracy = 0.687 | Test Accuracy = 0.630\n",
      "d = 4   | Training Accuracy = 0.825 | Test Accuracy = 0.784\n",
      "d = 5   | Training Accuracy = 0.851 | Test Accuracy = 0.880\n",
      "i-th digit: 3, j-th digit: 4\n",
      "d = 0   | Training Accuracy = 0.674 | Test Accuracy = 0.669\n",
      "d = 1   | Training Accuracy = 0.545 | Test Accuracy = 0.464\n",
      "d = 2   | Training Accuracy = 0.733 | Test Accuracy = 0.751\n",
      "d = 3   | Training Accuracy = 0.844 | Test Accuracy = 0.803\n",
      "d = 4   | Training Accuracy = 0.788 | Test Accuracy = 0.746\n",
      "d = 5   | Training Accuracy = 0.885 | Test Accuracy = 0.875\n",
      "i-th digit: 3, j-th digit: 5\n",
      "d = 0   | Training Accuracy = 0.535 | Test Accuracy = 0.584\n",
      "d = 1   | Training Accuracy = 0.585 | Test Accuracy = 0.562\n",
      "d = 2   | Training Accuracy = 0.625 | Test Accuracy = 0.666\n",
      "d = 3   | Training Accuracy = 0.765 | Test Accuracy = 0.759\n",
      "d = 4   | Training Accuracy = 0.695 | Test Accuracy = 0.765\n",
      "d = 5   | Training Accuracy = 0.79  | Test Accuracy = 0.781\n",
      "i-th digit: 3, j-th digit: 6\n",
      "d = 0   | Training Accuracy = 0.782 | Test Accuracy = 0.793\n",
      "d = 1   | Training Accuracy = 0.737 | Test Accuracy = 0.639\n",
      "d = 2   | Training Accuracy = 0.782 | Test Accuracy = 0.759\n",
      "d = 3   | Training Accuracy = 0.806 | Test Accuracy = 0.75\n",
      "d = 4   | Training Accuracy = 0.816 | Test Accuracy = 0.788\n",
      "d = 5   | Training Accuracy = 0.856 | Test Accuracy = 0.798\n",
      "i-th digit: 3, j-th digit: 7\n",
      "d = 0   | Training Accuracy = 0.672 | Test Accuracy = 0.584\n",
      "d = 1   | Training Accuracy = 0.793 | Test Accuracy = 0.797\n",
      "d = 2   | Training Accuracy = 0.708 | Test Accuracy = 0.632\n",
      "d = 3   | Training Accuracy = 0.811 | Test Accuracy = 0.821\n",
      "d = 4   | Training Accuracy = 0.771 | Test Accuracy = 0.681\n",
      "d = 5   | Training Accuracy = 0.914 | Test Accuracy = 0.893\n",
      "i-th digit: 3, j-th digit: 8\n",
      "d = 0   | Training Accuracy = 0.537 | Test Accuracy = 0.486\n",
      "d = 1   | Training Accuracy = 0.783 | Test Accuracy = 0.704\n",
      "d = 2   | Training Accuracy = 0.693 | Test Accuracy = 0.681\n",
      "d = 3   | Training Accuracy = 0.809 | Test Accuracy = 0.731\n",
      "d = 4   | Training Accuracy = 0.778 | Test Accuracy = 0.822\n",
      "d = 5   | Training Accuracy = 0.879 | Test Accuracy = 0.831\n",
      "i-th digit: 3, j-th digit: 9\n",
      "d = 0   | Training Accuracy = 0.524 | Test Accuracy = 0.509\n",
      "d = 1   | Training Accuracy = 0.539 | Test Accuracy = 0.538\n",
      "d = 2   | Training Accuracy = 0.651 | Test Accuracy = 0.614\n",
      "d = 3   | Training Accuracy = 0.715 | Test Accuracy = 0.7\n",
      "d = 4   | Training Accuracy = 0.808 | Test Accuracy = 0.804\n",
      "d = 5   | Training Accuracy = 0.808 | Test Accuracy = 0.795\n",
      "i-th digit: 4, j-th digit: 5\n",
      "d = 0   | Training Accuracy = 0.544 | Test Accuracy = 0.573\n",
      "d = 1   | Training Accuracy = 0.573 | Test Accuracy = 0.578\n",
      "d = 2   | Training Accuracy = 0.710 | Test Accuracy = 0.679\n",
      "d = 3   | Training Accuracy = 0.808 | Test Accuracy = 0.820\n",
      "d = 4   | Training Accuracy = 0.740 | Test Accuracy = 0.747\n",
      "d = 5   | Training Accuracy = 0.754 | Test Accuracy = 0.735\n",
      "i-th digit: 4, j-th digit: 6\n",
      "d = 0   | Training Accuracy = 0.582 | Test Accuracy = 0.566\n",
      "d = 1   | Training Accuracy = 0.728 | Test Accuracy = 0.738\n",
      "d = 2   | Training Accuracy = 0.883 | Test Accuracy = 0.871\n",
      "d = 3   | Training Accuracy = 0.907 | Test Accuracy = 0.891\n",
      "d = 4   | Training Accuracy = 0.825 | Test Accuracy = 0.798\n",
      "d = 5   | Training Accuracy = 0.815 | Test Accuracy = 0.812\n",
      "i-th digit: 4, j-th digit: 7\n",
      "d = 0   | Training Accuracy = 0.511 | Test Accuracy = 0.495\n",
      "d = 1   | Training Accuracy = 0.656 | Test Accuracy = 0.683\n",
      "d = 2   | Training Accuracy = 0.850 | Test Accuracy = 0.831\n",
      "d = 3   | Training Accuracy = 0.894 | Test Accuracy = 0.821\n",
      "d = 4   | Training Accuracy = 0.775 | Test Accuracy = 0.752\n",
      "d = 5   | Training Accuracy = 0.859 | Test Accuracy = 0.831\n",
      "i-th digit: 4, j-th digit: 8\n",
      "d = 0   | Training Accuracy = 0.753 | Test Accuracy = 0.706\n",
      "d = 1   | Training Accuracy = 0.556 | Test Accuracy = 0.474\n",
      "d = 2   | Training Accuracy = 0.546 | Test Accuracy = 0.474\n",
      "d = 3   | Training Accuracy = 0.738 | Test Accuracy = 0.646\n",
      "d = 4   | Training Accuracy = 0.798 | Test Accuracy = 0.748\n",
      "d = 5   | Training Accuracy = 0.837 | Test Accuracy = 0.832\n",
      "i-th digit: 4, j-th digit: 9\n",
      "d = 0   | Training Accuracy = 0.533 | Test Accuracy = 0.497\n",
      "d = 1   | Training Accuracy = 0.567 | Test Accuracy = 0.531\n",
      "d = 2   | Training Accuracy = 0.533 | Test Accuracy = 0.497\n",
      "d = 3   | Training Accuracy = 0.706 | Test Accuracy = 0.712\n",
      "d = 4   | Training Accuracy = 0.644 | Test Accuracy = 0.487\n",
      "d = 5   | Training Accuracy = 0.682 | Test Accuracy = 0.604\n",
      "i-th digit: 5, j-th digit: 6\n",
      "d = 0   | Training Accuracy = 0.510 | Test Accuracy = 0.531\n",
      "d = 1   | Training Accuracy = 0.851 | Test Accuracy = 0.813\n",
      "d = 2   | Training Accuracy = 0.728 | Test Accuracy = 0.768\n",
      "d = 3   | Training Accuracy = 0.760 | Test Accuracy = 0.649\n",
      "d = 4   | Training Accuracy = 0.813 | Test Accuracy = 0.790\n",
      "d = 5   | Training Accuracy = 0.898 | Test Accuracy = 0.915\n",
      "i-th digit: 5, j-th digit: 7\n",
      "d = 0   | Training Accuracy = 0.722 | Test Accuracy = 0.755\n",
      "d = 1   | Training Accuracy = 0.789 | Test Accuracy = 0.778\n",
      "d = 2   | Training Accuracy = 0.631 | Test Accuracy = 0.636\n",
      "d = 3   | Training Accuracy = 0.789 | Test Accuracy = 0.75\n",
      "d = 4   | Training Accuracy = 0.799 | Test Accuracy = 0.835\n",
      "d = 5   | Training Accuracy = 0.933 | Test Accuracy = 0.920\n",
      "i-th digit: 5, j-th digit: 8\n",
      "d = 0   | Training Accuracy = 0.502 | Test Accuracy = 0.402\n",
      "d = 1   | Training Accuracy = 0.794 | Test Accuracy = 0.756\n",
      "d = 2   | Training Accuracy = 0.740 | Test Accuracy = 0.698\n",
      "d = 3   | Training Accuracy = 0.729 | Test Accuracy = 0.804\n",
      "d = 4   | Training Accuracy = 0.789 | Test Accuracy = 0.767\n",
      "d = 5   | Training Accuracy = 0.805 | Test Accuracy = 0.820\n",
      "i-th digit: 5, j-th digit: 9\n",
      "d = 0   | Training Accuracy = 0.515 | Test Accuracy = 0.575\n",
      "d = 1   | Training Accuracy = 0.636 | Test Accuracy = 0.603\n",
      "d = 2   | Training Accuracy = 0.642 | Test Accuracy = 0.564\n",
      "d = 3   | Training Accuracy = 0.842 | Test Accuracy = 0.865\n",
      "d = 4   | Training Accuracy = 0.752 | Test Accuracy = 0.720\n",
      "d = 5   | Training Accuracy = 0.789 | Test Accuracy = 0.715\n",
      "i-th digit: 6, j-th digit: 7\n",
      "d = 0   | Training Accuracy = 0.791 | Test Accuracy = 0.716\n",
      "d = 1   | Training Accuracy = 0.767 | Test Accuracy = 0.766\n",
      "d = 2   | Training Accuracy = 0.857 | Test Accuracy = 0.850\n",
      "d = 3   | Training Accuracy = 0.758 | Test Accuracy = 0.731\n",
      "d = 4   | Training Accuracy = 0.881 | Test Accuracy = 0.900\n",
      "d = 5   | Training Accuracy = 0.886 | Test Accuracy = 0.815\n",
      "i-th digit: 6, j-th digit: 8\n",
      "d = 0   | Training Accuracy = 0.508 | Test Accuracy = 0.471\n",
      "d = 1   | Training Accuracy = 0.673 | Test Accuracy = 0.626\n",
      "d = 2   | Training Accuracy = 0.657 | Test Accuracy = 0.719\n",
      "d = 3   | Training Accuracy = 0.593 | Test Accuracy = 0.584\n",
      "d = 4   | Training Accuracy = 0.647 | Test Accuracy = 0.509\n",
      "d = 5   | Training Accuracy = 0.866 | Test Accuracy = 0.836\n",
      "i-th digit: 6, j-th digit: 9\n",
      "d = 0   | Training Accuracy = 0.505 | Test Accuracy = 0.504\n",
      "d = 1   | Training Accuracy = 0.531 | Test Accuracy = 0.553\n",
      "d = 2   | Training Accuracy = 0.807 | Test Accuracy = 0.75\n",
      "d = 3   | Training Accuracy = 0.770 | Test Accuracy = 0.779\n",
      "d = 4   | Training Accuracy = 0.817 | Test Accuracy = 0.715\n",
      "d = 5   | Training Accuracy = 0.906 | Test Accuracy = 0.857\n",
      "i-th digit: 7, j-th digit: 8\n",
      "d = 0   | Training Accuracy = 0.557 | Test Accuracy = 0.469\n",
      "d = 1   | Training Accuracy = 0.562 | Test Accuracy = 0.474\n",
      "d = 2   | Training Accuracy = 0.706 | Test Accuracy = 0.685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d = 3   | Training Accuracy = 0.822 | Test Accuracy = 0.741\n",
      "d = 4   | Training Accuracy = 0.855 | Test Accuracy = 0.812\n",
      "d = 5   | Training Accuracy = 0.677 | Test Accuracy = 0.610\n",
      "i-th digit: 7, j-th digit: 9\n",
      "d = 0   | Training Accuracy = 0.572 | Test Accuracy = 0.527\n",
      "d = 1   | Training Accuracy = 0.708 | Test Accuracy = 0.650\n",
      "d = 2   | Training Accuracy = 0.760 | Test Accuracy = 0.748\n",
      "d = 3   | Training Accuracy = 0.760 | Test Accuracy = 0.733\n",
      "d = 4   | Training Accuracy = 0.732 | Test Accuracy = 0.719\n",
      "d = 5   | Training Accuracy = 0.854 | Test Accuracy = 0.857\n",
      "i-th digit: 8, j-th digit: 9\n",
      "d = 0   | Training Accuracy = 0.513 | Test Accuracy = 0.476\n",
      "d = 1   | Training Accuracy = 0.518 | Test Accuracy = 0.537\n",
      "d = 2   | Training Accuracy = 0.724 | Test Accuracy = 0.587\n",
      "d = 3   | Training Accuracy = 0.772 | Test Accuracy = 0.768\n",
      "d = 4   | Training Accuracy = 0.777 | Test Accuracy = 0.768\n",
      "d = 5   | Training Accuracy = 0.835 | Test Accuracy = 0.837\n"
     ]
    }
   ],
   "source": [
    "pairwise_matrix=np.identity(10)\n",
    "\n",
    "d_list=[]\n",
    "train_acc_list=[]\n",
    "test_acc_list=[]\n",
    "        \n",
    "for digit_i in range(pairwise_matrix.shape[0]):\n",
    "    for digit_j in range(pairwise_matrix.shape[1]):\n",
    "        if pairwise_matrix[digit_i, digit_j]==0:\n",
    "            new_train_set, new_test_set = create_pairwise_dataset(digit_i, digit_j, train_set, valid_set)\n",
    "            X_train, y_train = new_train_set[0], new_train_set[1]\n",
    "            X_test, y_test = new_test_set[0], new_test_set[1]\n",
    "            \n",
    "            #uptade conditions\n",
    "            pairwise_matrix[digit_i, digit_j]=1\n",
    "            pairwise_matrix[digit_j, digit_i]=1\n",
    "\n",
    "            #calculate for each dataset and each k, training and test accuracy\n",
    "            print('i-th digit: {a}, j-th digit: {b}'.format(a=digit_i, b=digit_j))\n",
    "            for d in [0,1,2,3,4,5]:\n",
    "                \n",
    "                #create layers\n",
    "                #layers = [784, 1024, 1024, 1024, 1024, 1024, 1] \n",
    "                layers = [784] #init\n",
    "                layers+=(d*[100]) #should be 1024\n",
    "                layers.append(1)\n",
    "                \n",
    "                #train model\n",
    "                model = Memorization(layers, k=2)\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                #predict and calculate accuracy\n",
    "                train_acc = model.accuracy(X_train, y_train)\n",
    "                test_acc = model.accuracy(X_test, y_test)\n",
    "                \n",
    "                #store data\n",
    "                d_list.append(d)\n",
    "                train_acc_list.append(train_acc)\n",
    "                test_acc_list.append(test_acc)\n",
    "                \n",
    "                print(\"d = \" + (str(d) + \"  \")[:3]\n",
    "          + \" | Training Accuracy = \" + (str(train_acc) + \"   \")[:5] \n",
    "          + \" | Test Accuracy = \" + str(test_acc)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_acc_list = np.abs(np.array(test_acc_list)-np.array(train_acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display graph\n",
    "plt.plot(d_list, train_acc_list, 'b+', label='training')\n",
    "plt.plot(d_list, test_acc_list, 'r+', label='test')\n",
    "plt.plot(d_list, diff_acc_list, 'g+', label='difference')\n",
    "plt.title('The effect of depth (d) on networks with small lookup tables (k = 2) for Pairwise-MNIST')\n",
    "plt.legend()\n",
    "plt.xlabel('log2(d-1)')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expérimentation n°7\n",
    "\n",
    "L'objectif de l'expérience est de reproduire le modèle de mémorisation sur le dataset CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = X_train[:6000], y_train[:6000]\n",
    "X_test, y_test = X_test[:6000], y_test[:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "X_train = X_train.astype(int)\n",
    "X_test = X_test.astype(int)\n",
    "\n",
    "X_train = X_train.reshape(-1,32*32*3)\n",
    "X_test = X_test.reshape(-1,32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fonction servant à binariser les valeurs de chaque pixels d'une image\n",
    "def binarise(img, s=0.5):\n",
    "    nbr_pixels = len(img)\n",
    "    L=np.zeros(nbr_pixels)\n",
    "    for i in range(nbr_pixels) :\n",
    "        if img[i]>s :\n",
    "            L[i]=1\n",
    "        else :\n",
    "            L[i]=0\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Binarisation du dataset\n",
    "for i in range (X_train.shape[0]):\n",
    "    X_train[i]=binarise(X_train[i])\n",
    "\n",
    "for i in range (X_test.shape[0]):\n",
    "    X_test[i]=binarise(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = (y_train >= 5).astype(int)\n",
    "y_test = (y_test >= 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0],)\n",
    "y_test = y_test.reshape(y_test.shape[0],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 0s 242us/step - loss: 0.7006 - acc: 0.5445\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 0s 137us/step - loss: 0.6475 - acc: 0.6265\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 0s 137us/step - loss: 0.5975 - acc: 0.6900\n",
      "Evaluating...\n",
      "2000/2000 [==============================] - 0s 85us/step\n"
     ]
    }
   ],
   "source": [
    "# Test du modèle : CONV NET\n",
    "\n",
    "X_train = X_train.reshape(-1, 32, 32, 3)\n",
    "X_test = X_test.reshape(-1, 32, 32, 3)\n",
    "\n",
    "#should have images in form (32, 32, 3)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "cnn = models.Sequential()\n",
    "cnn.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))\n",
    "cnn.add(layers.MaxPooling2D((2,2)))\n",
    "cnn.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "cnn.add(layers.Flatten())\n",
    "cnn.add(layers.Dense(16, activation = 'relu'))\n",
    "cnn.add(layers.Dense(1, activation='sigmoid'))\n",
    "rms=optimizers.RMSprop()\n",
    "cnn.compile(loss='binary_crossentropy',optimizer=rms,metrics=['acc'])\n",
    "\n",
    "print('Training...')\n",
    "history = cnn.fit(X_train, y_train, epochs=3, batch_size=32)\n",
    "\n",
    "print('Evaluating...')\n",
    "cnn_train_acc = history.history['acc']\n",
    "_, cnn_test_acc = cnn.evaluate(X_test, y_test)\n",
    "list_results.append((\"CONV NET\", cnn_train_acc[-1], cnn_test_acc))\n",
    "\n",
    "X_train = X_train.reshape(-1,32*32*3)\n",
    "X_test = X_test.reshape(-1,32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test du modèle : Random Forest (300 Trees)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 300)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_train_accuracy = accuracy_score(rf.predict(X_train), y_train)\n",
    "rf_test_accuracy = accuracy_score(rf.predict(X_test), y_test)\n",
    "\n",
    "list_results.append((\"Random Forest (300 Trees)\", rf_train_accuracy, rf_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test du modèle : 5-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_5 = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn_5.fit(X_train, y_train)\n",
    "knn_5_train_accuracy = accuracy_score(knn_5.predict(X_train), y_train)\n",
    "knn_5_test_accuracy = accuracy_score(knn_5.predict(X_test), y_test)\n",
    "\n",
    "list_results.append((\"5-Nearest Neighbors\", knn_5_train_accuracy, knn_5_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test du modèle : 1-Nearest Neighbors\n",
    "knn_1 = KNeighborsClassifier(n_neighbors = 1)\n",
    "knn_1.fit(X_train, y_train)\n",
    "knn_1_train_accuracy = accuracy_score(knn_1.predict(X_train), y_train)\n",
    "knn_1_test_accuracy = accuracy_score(knn_1.predict(X_test), y_test)\n",
    "\n",
    "list_results.append((\"1-Nearest Neighbors\", knn_1_train_accuracy, knn_1_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test du modèle : Memorization\n",
    "#5 hidden layers of 1024 luts\n",
    "#k=10\n",
    "layers=[784, 100, 100, 100, 100, 100, 1]\n",
    "memo = Memorization(layers, k=10)\n",
    "memo.fit(X_train, y_train)\n",
    "memo_train_accuracy = accuracy_score(memo.predict(X_train), y_train)\n",
    "memo_test_accuracy = accuracy_score(memo.predict(X_test), y_test)\n",
    "\n",
    "list_results.append((\"Memorization\", memo_train_accuracy, memo_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test du modèle : Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "lr_train_accuracy = accuracy_score(lr.predict(X_train), y_train)\n",
    "lr_test_accuracy = accuracy_score(lr.predict(X_test), y_test)\n",
    "\n",
    "list_results.append((\"Logistic Regression\", lr_train_accuracy, lr_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test du modèle : Naïve Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_train_accuracy = accuracy_score(nb.predict(X_train), y_train)\n",
    "nb_test_accuracy = accuracy_score(nb.predict(X_test), y_test)\n",
    "\n",
    "list_results.append((\"Naïve Bayes\", nb_train_accuracy, nb_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test du modèle : Random Guess\n",
    "random_guess = lambda x : np.random.randint(2)\n",
    "rg_train_accuracy = accuracy_score([random_guess(x) for x in X_train], y_train)\n",
    "rg_test_accuracy = accuracy_score([random_guess(x) for x in X_test], y_test)\n",
    "\n",
    "\n",
    "list_results.append((\"Random Guess\", rg_train_accuracy, rg_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONV NET                  | Training Accuracy = 0.69   | Test Accuracy = 0.5935\n",
      "Random Forest (300 Trees) | Training Accuracy = 1.0    | Test Accuracy = 0.603\n",
      "5-Nearest Neighbors       | Training Accuracy = 0.702  | Test Accuracy = 0.5745\n",
      "1-Nearest Neighbors       | Training Accuracy = 1.0    | Test Accuracy = 0.575\n",
      "Memorization              | Training Accuracy = 0.943  | Test Accuracy = 0.5255\n",
      "Logistic Regression       | Training Accuracy = 1.0    | Test Accuracy = 0.5345\n",
      "Naïve Bayes               | Training Accuracy = 0.554  | Test Accuracy = 0.547\n",
      "Random Guess              | Training Accuracy = 0.5125 | Test Accuracy = 0.496\n"
     ]
    }
   ],
   "source": [
    "# Comparaison des modèles\n",
    "\n",
    "for name, train_acc, test_acc in list_results:\n",
    "    print((str(name) + \"                 \")[:25] \n",
    "          + \" | Training Accuracy = \" + (str(train_acc) + \"   \")[:6]\n",
    "          + \" | Test Accuracy = \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expérimentation n°8\n",
    "\n",
    "L'objectif de l'expérience est de garder la même architecture de réseau de l'expérience 7 et de l'appliquer à la tâche de séparation des catégories 1 à 1 (similaire à l'expérience 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = [X_train, y_train]\n",
    "test_set = [X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class i: 0, class j: 1\n",
      "k = 10  | Training Accuracy = 0.647 | Test Accuracy = 0.532\n",
      "class i: 0, class j: 2\n",
      "k = 10  | Training Accuracy = 0.589 | Test Accuracy = 0.524\n",
      "class i: 0, class j: 3\n",
      "k = 10  | Training Accuracy = 0.589 | Test Accuracy = 0.489\n",
      "class i: 0, class j: 4\n",
      "k = 10  | Training Accuracy = 0.584 | Test Accuracy = 0.535\n",
      "class i: 0, class j: 5\n",
      "k = 10  | Training Accuracy = 0.572 | Test Accuracy = 0.5\n",
      "class i: 0, class j: 6\n",
      "k = 10  | Training Accuracy = 0.587 | Test Accuracy = 0.531\n",
      "class i: 0, class j: 7\n",
      "k = 10  | Training Accuracy = 0.640 | Test Accuracy = 0.519\n",
      "class i: 0, class j: 8\n",
      "k = 10  | Training Accuracy = 0.585 | Test Accuracy = 0.504\n",
      "class i: 0, class j: 9\n",
      "k = 10  | Training Accuracy = 0.749 | Test Accuracy = 0.573\n",
      "class i: 1, class j: 2\n",
      "k = 10  | Training Accuracy = 0.652 | Test Accuracy = 0.532\n",
      "class i: 1, class j: 3\n",
      "k = 10  | Training Accuracy = 0.633 | Test Accuracy = 0.525\n",
      "class i: 1, class j: 4\n",
      "k = 10  | Training Accuracy = 0.652 | Test Accuracy = 0.561\n",
      "class i: 1, class j: 5\n",
      "k = 10  | Training Accuracy = 0.637 | Test Accuracy = 0.513\n",
      "class i: 1, class j: 6\n",
      "k = 10  | Training Accuracy = 0.651 | Test Accuracy = 0.551\n",
      "class i: 1, class j: 7\n",
      "k = 10  | Training Accuracy = 0.628 | Test Accuracy = 0.516\n",
      "class i: 1, class j: 8\n",
      "k = 10  | Training Accuracy = 0.645 | Test Accuracy = 0.528\n",
      "class i: 1, class j: 9\n",
      "k = 10  | Training Accuracy = 0.733 | Test Accuracy = 0.557\n",
      "class i: 2, class j: 3\n",
      "k = 10  | Training Accuracy = 0.594 | Test Accuracy = 0.503\n",
      "class i: 2, class j: 4\n",
      "k = 10  | Training Accuracy = 0.554 | Test Accuracy = 0.516\n",
      "class i: 2, class j: 5\n",
      "k = 10  | Training Accuracy = 0.585 | Test Accuracy = 0.517\n",
      "class i: 2, class j: 6\n",
      "k = 10  | Training Accuracy = 0.559 | Test Accuracy = 0.513\n",
      "class i: 2, class j: 7\n",
      "k = 10  | Training Accuracy = 0.644 | Test Accuracy = 0.536\n",
      "class i: 2, class j: 8\n",
      "k = 10  | Training Accuracy = 0.582 | Test Accuracy = 0.515\n",
      "class i: 2, class j: 9\n",
      "k = 10  | Training Accuracy = 0.753 | Test Accuracy = 0.568\n",
      "class i: 3, class j: 4\n",
      "k = 10  | Training Accuracy = 0.591 | Test Accuracy = 0.531\n",
      "class i: 3, class j: 5\n",
      "k = 10  | Training Accuracy = 0.582 | Test Accuracy = 0.495\n",
      "class i: 3, class j: 6\n",
      "k = 10  | Training Accuracy = 0.597 | Test Accuracy = 0.509\n",
      "class i: 3, class j: 7\n",
      "k = 10  | Training Accuracy = 0.627 | Test Accuracy = 0.530\n",
      "class i: 3, class j: 8\n",
      "k = 10  | Training Accuracy = 0.594 | Test Accuracy = 0.499\n",
      "class i: 3, class j: 9\n",
      "k = 10  | Training Accuracy = 0.746 | Test Accuracy = 0.573\n",
      "class i: 4, class j: 5\n",
      "k = 10  | Training Accuracy = 0.583 | Test Accuracy = 0.543\n",
      "class i: 4, class j: 6\n",
      "k = 10  | Training Accuracy = 0.547 | Test Accuracy = 0.484\n",
      "class i: 4, class j: 7\n",
      "k = 10  | Training Accuracy = 0.639 | Test Accuracy = 0.555\n",
      "class i: 4, class j: 8\n",
      "k = 10  | Training Accuracy = 0.575 | Test Accuracy = 0.543\n",
      "class i: 4, class j: 9\n",
      "k = 10  | Training Accuracy = 0.753 | Test Accuracy = 0.584\n",
      "class i: 5, class j: 6\n",
      "k = 10  | Training Accuracy = 0.585 | Test Accuracy = 0.537\n",
      "class i: 5, class j: 7\n",
      "k = 10  | Training Accuracy = 0.633 | Test Accuracy = 0.510\n",
      "class i: 5, class j: 8\n",
      "k = 10  | Training Accuracy = 0.583 | Test Accuracy = 0.498\n",
      "class i: 5, class j: 9\n",
      "k = 10  | Training Accuracy = 0.744 | Test Accuracy = 0.575\n",
      "class i: 6, class j: 7\n",
      "k = 10  | Training Accuracy = 0.644 | Test Accuracy = 0.553\n",
      "class i: 6, class j: 8\n",
      "k = 10  | Training Accuracy = 0.580 | Test Accuracy = 0.519\n",
      "class i: 6, class j: 9\n",
      "k = 10  | Training Accuracy = 0.747 | Test Accuracy = 0.594\n",
      "class i: 7, class j: 8\n",
      "k = 10  | Training Accuracy = 0.638 | Test Accuracy = 0.512\n",
      "class i: 7, class j: 9\n",
      "k = 10  | Training Accuracy = 0.742 | Test Accuracy = 0.534\n",
      "class i: 8, class j: 9\n",
      "k = 10  | Training Accuracy = 0.748 | Test Accuracy = 0.573\n"
     ]
    }
   ],
   "source": [
    "pairwise_matrix=np.identity(10)\n",
    "\n",
    "k_list=[]\n",
    "train_acc_list=[]\n",
    "test_acc_list=[]\n",
    "        \n",
    "for class_i in range(pairwise_matrix.shape[0]):\n",
    "    for class_j in range(pairwise_matrix.shape[1]):\n",
    "        if pairwise_matrix[class_i, class_j]==0:\n",
    "            new_train_set, new_test_set = create_pairwise_dataset(class_i, class_j, train_set, test_set)\n",
    "            X_train, y_train = new_train_set[0], new_train_set[1]\n",
    "            X_test, y_test = new_test_set[0], new_test_set[1]\n",
    "            \n",
    "            #uptade conditions\n",
    "            pairwise_matrix[class_i, class_j]=1\n",
    "            pairwise_matrix[class_j, class_i]=1\n",
    "\n",
    "            #calculate for each dataset and each k, training and test accuracy\n",
    "            print('class i: {a}, class j: {b}'.format(a=class_i, b=class_j))\n",
    "            \n",
    "            k=10\n",
    "            layers=[784, 100, 100, 100, 100, 100, 1] #should be 1024\n",
    "            model = Memorization(layers, k)\n",
    "            model.fit(X_train, y_train)\n",
    "                \n",
    "            train_acc = model.accuracy(X_train, y_train)\n",
    "            test_acc = model.accuracy(X_test, y_test)\n",
    "                \n",
    "            k_list.append(k)\n",
    "            train_acc_list.append(train_acc)\n",
    "            test_acc_list.append(test_acc)\n",
    "                \n",
    "            print(\"k = \" + (str(k) + \"  \")[:3]\n",
    "          + \" | Training Accuracy = \" + (str(train_acc) + \"   \")[:5] \n",
    "          + \" | Test Accuracy = \" + str(test_acc)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expérimentation n°9\n",
    "\n",
    "L'objectif de trier les points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pair of points\n",
    "#encode each point in a 10-bit number\n",
    "# example point A = (0010111111, 0001010101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def circle_cond(x, y):\n",
    "    if x**2 + y**2 <= (1.6**2):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_X_to_coord(X, dict_loc):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i in range(X.shape[0]):\n",
    "        s=\"\"\n",
    "        for j in range(X.shape[1]):\n",
    "            s+=str(X[i][j])\n",
    "        coord = dict_loc[s]\n",
    "        x.append(coord[0])\n",
    "        y.append(coord[1])\n",
    "    return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_circle(X, y, ax, title='title'):\n",
    "    \n",
    "    x_g, y_g = transform_X_to_coord(X[tuple(np.where(y==0))], dict_loc)\n",
    "    x_b, y_b = transform_X_to_coord(X[tuple(np.where(y==1))], dict_loc)\n",
    "\n",
    "    ax.plot(x_b, y_b, 'b+')\n",
    "    ax.plot(x_g, y_g, 'g+')\n",
    "    ax.set_xlim([-2.0,2.0])\n",
    "    ax.set_ylim([-2.0,2.0])\n",
    "    ax.set_title(title);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "x_set = []\n",
    "y_set = []\n",
    "#Create a 100x100 grid\n",
    "grid_space = np.linspace(-2.0, 2.0, 100)\n",
    "\n",
    "grid=np.zeros((100,100))\n",
    "dict_loc = {}\n",
    "\n",
    "list_bin=[]\n",
    "for i in range(100):\n",
    "    list_bin.append((\"0\"*10 + str(bin(i))[2:])[-10:])\n",
    "\n",
    "nb_exemples = 10000 #must be <10000 (100*100 points)\n",
    "#generate 100*100 points\n",
    "for ex in range(nb_exemples):\n",
    "    x_idx = random.randint(0,99)\n",
    "    y_idx = random.randint(0,99)\n",
    "    if grid[x_idx][y_idx]==0:\n",
    "        p_x = np.array([int(list_bin[x_idx][e]) for e in range(10)])\n",
    "        p_y = np.array([int(list_bin[y_idx][e]) for e in range(10)])\n",
    "        encoded_point = np.concatenate((p_x, p_y), axis=0)\n",
    "        x_set.append(encoded_point)\n",
    "        x = grid_space[x_idx]\n",
    "        y = grid_space[y_idx]\n",
    "        str_encoded_point=\"\"\n",
    "        for k in range(20):\n",
    "            str_encoded_point+=str(encoded_point[k])\n",
    "        dict_loc[str_encoded_point]=[x, y]\n",
    "        true_y = circle_cond(x, y)\n",
    "    \n",
    "        y_set.append(true_y)\n",
    "        \n",
    "        #update\n",
    "        grid[x_idx][y_idx]==1\n",
    "    \n",
    "x_set = np.array(x_set, dtype=int)\n",
    "y_set =np.array(y_set, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_set, y_set, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = [20]\n",
    "layers += (32*[2048])\n",
    "layers.append(1)\n",
    "\n",
    "train_preds = {}\n",
    "test_preds = {}\n",
    "\n",
    "k_list = [2, 6, 10]\n",
    "\n",
    "for k in k_list:\n",
    "    #train model\n",
    "    model = Memorization(layers, k)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #predict and calculate accuracy\n",
    "    train_acc = model.accuracy(X_train, y_train)\n",
    "    test_acc = model.accuracy(X_test, y_test)\n",
    "\n",
    "    #store data\n",
    "    train_y_pred = model.predict(X_train)\n",
    "    test_y_pred = model.predict(X_test)\n",
    "    train_preds[k] = train_y_pred\n",
    "    test_preds[k] = test_y_pred\n",
    "\n",
    "    print(\"k = \" + (str(k) + \"  \")[:3]\n",
    "        + \" | Training Accuracy = \" + (str(train_acc) + \"   \")[:5] \n",
    "        + \" | Test Accuracy = \" + str(test_acc)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "fig.subplots_adjust(wspace=0.1)\n",
    "fig.suptitle('ground truth', fontsize=20)\n",
    "\n",
    "plot_circle(X_train, y_train, axs[0], title='training')\n",
    "plot_circle(X_test, y_test, axs[1], title='test')\n",
    "\n",
    "for k in k_list:\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    fig.subplots_adjust(wspace=0.1)\n",
    "    fig.suptitle('k={}'.format(k), fontsize=20)\n",
    "\n",
    "    plot_circle(X_train, train_preds[k], axs[0], title='training')\n",
    "    plot_circle(X_test, test_preds[k], axs[1], title='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Améliorations\n",
    "\n",
    "L'objectif de cette amélioration est de ne calculer que les luts utiles pour l'entraînement et la prédictions. Le modèle reste donc inchangé, seul le temps de calcul se trouve amélioré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Improved_Memorization(Memorization):\n",
    "    def __init__(self, layers, k):\n",
    "        super().__init__(layers, k)\n",
    "        \n",
    "        useful = [list(range(layers[-1]))]\n",
    "        for i in range(len(self.list_luts) - 1, -1, -1):\n",
    "            x = []\n",
    "            for j in useful[-1]:\n",
    "                x += list(self.list_luts[i][j])\n",
    "            useful.append(sorted(list(set(x))))\n",
    "        \n",
    "        self.useful = list(reversed(useful)) # Ensemble des luts dont le calcul est utile, par couche\n",
    "        \n",
    "    \n",
    "    def fit(self, X_train, y_train, print_training_accuracy = False):\n",
    "        #Display training accuracy for the first layer (layer 0)\n",
    "        if print_training_accuracy:\n",
    "                print(\"Layer = \" + str(0) \n",
    "                      + \" | Lut count = \" + (str(self.layers[0]) + \"    \")[:5]\n",
    "                      + \" | Useful luts = \" + (str(len(self.useful[0])) + \"    \")[:5]\n",
    "                      + \" | Training Accuracy = \" + str(self.accuracy(X_train, y_train)))\n",
    "                \n",
    "        n = len(X_train)\n",
    "        \n",
    "        list_computed = [X_train] #initialise la liste des couches qui vont être calculées\n",
    "        self.list_link = [] # liste des liaisons entre luts\n",
    "\n",
    "        # Entraînement couche par couche\n",
    "        for layer in range(1, len(self.layers)): #numero de la couche\n",
    "            layer_luts = self.list_luts[layer - 1] #liste des luts de la couche précédente et de taille k (combinaison aléatoire)\n",
    "\n",
    "            last_computed_layer = list_computed[-1] #récupère la dernière couche\n",
    "\n",
    "            link = []\n",
    "            next_computed_layer = [[0 for x in range(self.layers[layer])] for y in range(n)] #initialiste la couche suivante \n",
    "                                                                                             #(taille de la couche suivant * nombre d'exemples dans le dataset)\n",
    "            \n",
    "            for i in range(self.layers[layer]): #parcourt la taille de la couche pour chaque couche\n",
    "                if i in self.useful[layer]:\n",
    "                    dict_positif = self.dict.copy() #init du dictionnaire stockant le nombre de valeurs positives\n",
    "                    dict_negatif = self.dict.copy() #init du dictionnaire stockant le nombre de valeurs négatives\n",
    "\n",
    "                    for j in range(n): #parcourt le nombre d'exemples dans le dataset\n",
    "                        s = \"\"\n",
    "                        for z in range(self.k): #parcourt la taille k pour chaque exemple\n",
    "                            try :\n",
    "                                s += str(last_computed_layer[j][layer_luts[i][z]]) #donne la valeur binaire pour chaque exemple (j) grâce à la combinaison aléatoire des luts de la couche précédente\n",
    "                            except :\n",
    "                                print(layer_luts[i][z])\n",
    "                        next_computed_layer[j][i] = s #stocke la valeur binaire dans la nouvelle couche à la position (j=numero d'exemples, i=numero dans la taille de la couche)\n",
    "                        dict_negatif[s] += (y_train[j] == 0).astype(int) #stocke dans le dict neg pour la clé binaire, le nombre de valeurs negatives dans le dataset\n",
    "                        dict_positif[s] += (y_train[j] == 1).astype(int) #stocke dans le dict pos pour la clé binaire, le nombre de valeurs positive dans le dataset\n",
    "\n",
    "                    dict_ = self.dict.copy()\n",
    "\n",
    "                    #prédiction finale obtenu par la comparaison du nombre de valeurs positives par rapport aux nombres de valeurs négatives\n",
    "                    for l in dict_.keys():\n",
    "                        if dict_positif[l] > dict_negatif[l]:\n",
    "                            dict_[l] = 1\n",
    "                        elif dict_positif[l] < dict_negatif[l]:\n",
    "                            dict_[l] = 0\n",
    "                        else :\n",
    "                            dict_[l] = np.random.randint(2)\n",
    "\n",
    "                    #attribut la valeur finale pour la nouvelle couche à la position j(num exemple pour chaque exemple), i(num taille de la couche)\n",
    "                    for j in range(n): #reparcourt le nombre d'exemples dans le dataset\n",
    "                        next_computed_layer[j][i] = dict_[next_computed_layer[j][i]]\n",
    "\n",
    "                    link.append(dict_) #rajoute le dict des valeurs prédites 'dict_' dans une liste 'link'\n",
    "                else :\n",
    "                    link.append(0)\n",
    "\n",
    "            list_computed.append(next_computed_layer) #rajoute la nouvelle couche dans la liste 'list_computed'\n",
    "            self.list_link.append(link) #rajoute la liste 'link' dans la liste générale 'list_link'\n",
    "            \n",
    "            if print_training_accuracy:\n",
    "                print(\"Layer = \" + str(layer) \n",
    "                      + \" | Lut count = \" + (str(self.layers[layer]) + \"    \")[:5] \n",
    "                      + \" | Useful luts = \" + (str(len(self.useful[layer])) + \"    \")[:5]\n",
    "                      + \" | Training Accuracy = \" + str(self.accuracy(X_train, y_train)))\n",
    "                \n",
    "    \"\"\"\n",
    "    Prediction de la classe pour une entrée x.\n",
    "    \"\"\"\n",
    "    def one_prediction(self, x):   \n",
    "        list_computed = [x]\n",
    "\n",
    "        # Calcul couche par couche\n",
    "        for layer in range(len(self.list_link)):\n",
    "            layer_luts = self.list_luts[layer]\n",
    "            link = self.list_link[layer]\n",
    "            last_computed_layer = list_computed[-1]\n",
    "\n",
    "            next_computed_layer = []\n",
    "            for i in range(len(layer_luts)):\n",
    "                \n",
    "                if i in self.useful[layer +1]:\n",
    "                    s = \"\"\n",
    "                    for z in range(self.k):\n",
    "                        s += str(last_computed_layer[layer_luts[i][z]])\n",
    "                    next_computed_layer.append(link[i][s])\n",
    "                    \n",
    "                else:\n",
    "                    next_computed_layer.append(0)\n",
    "            list_computed.append(next_computed_layer)\n",
    "        \n",
    "        # Somme du nombre de 1 sur l'ensemble des luts de la dernière couche\n",
    "        resu = 0\n",
    "        for i in range(len(self.list_luts[len(self.list_link) - 1])):\n",
    "            resu += list_computed[-1][i]\n",
    "        \n",
    "        # Retourne 1 si il y a plus de 1 que de 0 sur l'ensemble des luts de la dernière couche (0 sinon)\n",
    "        return int(resu > len(self.useful[len(self.list_link)]) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = [784, 1024, 1024, 1024, 1024, 1024, 1] \n",
    "k = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Improved_Memorization(layers, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer = 0 | Lut count = 784   | Useful luts = 784   | Training Accuracy = 0.486\n",
      "Layer = 1 | Lut count = 1024  | Useful luts = 1024  | Training Accuracy = 0.825\n",
      "Layer = 2 | Lut count = 1024  | Useful luts = 985   | Training Accuracy = 0.948\n",
      "Layer = 3 | Lut count = 1024  | Useful luts = 418   | Training Accuracy = 0.985\n",
      "Layer = 4 | Lut count = 1024  | Useful luts = 64    | Training Accuracy = 0.998\n",
      "Layer = 5 | Lut count = 1024  | Useful luts = 8     | Training Accuracy = 0.999\n",
      "Layer = 6 | Lut count = 1     | Useful luts = 1     | Training Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, print_training_accuracy = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
